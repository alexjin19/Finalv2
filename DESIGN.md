There were MANY difficult design choices that we had to make in order to get a working mobile app audio recorder. At first, we followed one implementation guide which used class components in bare React Native to construct the audio recorder. This is an advanced way to create functions that are compatible with iOS and android, but the implementation of this technique proved cumbersome and complicated. We struggled with various errors, such as render errors, unhandled promise rejections, and undefined objects, as our understanding of bare React Native was not at the level needed to truly master class components. We spent almost a week debugging one render error related to importing components, which we ultimately debugged by guessing and checking which one of our 10 components was the issue. This made the process and timeline even more stressful. Ultimately, we got a UI to work in addition to writing the code for the intended functionality of our app. However, here again we ran into another problem. We had been building this app in Expo, which is designed to make react native easier to implement, but some of the packages we were using (namely react-native-audio-recorder-player) did not have full compatibility with Expo. Thus, in order to get our app to work as intended, we had to move our project from Expo to bare react native. We did not realize how tedious this would be when we started the project, but it involves numerous steps, package downloads, and advanced coding in the terminal that we do not yet have the skills for.

Thus, we ultimately switched from using the react-native-audio-recorder-player package to the Expo-AV audio package. This meant we scrapped the method of using class components altogether and decided to rebuild our project from scratch. Specifically, we started using functional components, and instead of following a tutorial step by step, we simply followed the reference guide to one of react native’s audio-visual packages called ‘expo-av’. We not only learned even more about Expo and React Native’s functionalities by doing this, but we also made progress on our app much faster.

This brings us to the actual design of our code. Our app has two main portions. First, is the functional component where all of the asynchronous functions are located. Second, is the css stylesheet. Within the functional component, we first create 2 react state variables which are initialized to null.

The first asynchronous function within the functional component is the startRecording function. This functions works by first setting the mySoundUri variable to null. This ensures that whenever you record a new recording, it clears the uri of the old audio stored in that variable and lets you record again. Second, this function then ensures that the correct permissions are allowed to use the phone mic. This is necessary because if we don’t have permission to use the mic, we can’t record. Afterwards, we use the audio.setaudiomodeasync function to make sure we can record on IOS and play the audio even if the phone is on silent mode. After creating the recording instance, which starts to record any audio detected, we set that equal to the myrecording variable using the setrecording function. Lastly, we have a ‘catch’ which catches errors and displays them in the terminal if any occur. By the end of this function, our recorder has ensured that audio is able to be recorded by the device, and audio starts to be recorded.

The next function is the stopRecording function. When the stop recording button is pressed, it stops the recording by calling the stopAndUnloadAsync function, which stops the recording and unloads the recorder from memory. The most important part of the stop recording function, though, is that it gets the uri of the recording and saves it into the mysounduri variable. Thus, by the end of this function, we have a complete audio recording that is saved to mysounduri.

This mysounduri is then used in the asynchronous playSound function, which gets the actual audio from the uri and plays it back to the user. Here, we ran into a difficult bug that only allowed sound to come out of the phone’s earpiece rather than the mic, making the playback super quiet (think listening to it on the phone). To debug this bug, we set allowsRecordingIOS to false (in stratRecording we set it to true). By setting allowsRecordIOS to false, we are essentially instructing the code to not run through the earpiece, since in this package  recording is captured through the earpiece. Thus, any sound is now sent to the mic, solving our problem.

In terms of UI design, we elected for a Yale themed look with two buttons: the combined start/stop recording button and the play sound button. We added play and stop icons to the buttons, and the functions we described above run when their respective button is clicked by the user. Furthermore, we also learned how to add images into expo apps, which is fairly different than in HTML. As such, we used this knowledge to add a Yale logo to our app. We then color coordinated every element to the Yale blue theme (#00356B). There’s a header that has the name of the app as well, and of course, we have to sign the app with our names: Alex Jin and James Leung. In building this UI, we learned how to coordinate the UI with the functions (such as getting functions to run upon a button being clicked). We also learned about many cool ways to customize and design our own UI, such as by researching different components and different ways to organize and nest them.

In making this mobile app, navigating this very difficult challenge allowed us to learn so much about a new language that we never would have been able to by following a cookie cutter template like building a website similar to finance. In addition, the debugging skills we learned will really help us with coding in the future. This ability to learn so much coding is why we pursued building a mobile app in a completely new language, despite knowing that the final product would not look as complex or ‘cool’ as other projects and that learning this new language would require significantly more time than working in other languages. Having finished now, we can definitively say that this is a project that we are both really excited and proud about.

https://stackoverflow.com/questions/67207450/how-can-i-play-a-sound-after-recording-in-react-native-expo